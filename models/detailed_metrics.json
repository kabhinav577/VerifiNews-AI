{
  "test_set_info": {
    "size": 4492,
    "real_samples": 2351,
    "fake_samples": 2141
  },
  "evaluation_info": {
    "date": "2025-12-01T14:27:28.948621",
    "device": "cpu",
    "models_evaluated": [
      "distilbert",
      "mobilebert"
    ]
  },
  "metrics": {
    "distilbert": {
      "model": "DistilBERT",
      "accuracy": 0.9984416740872663,
      "precision": 0.9984426627120186,
      "recall": 0.9984416740872663,
      "f1_score": 0.9984417221483568,
      "precision_binary": 0.9976679104477612,
      "recall_binary": 0.9990658570761326,
      "f1_binary": 0.9983663943990665,
      "precision_per_class": [
        0.9991482112436116,
        0.9976679104477612
      ],
      "recall_per_class": [
        0.9978732454274777,
        0.9990658570761326
      ],
      "f1_per_class": [
        0.998510321344967,
        0.9983663943990665
      ],
      "support_per_class": [
        2351,
        2141
      ],
      "avg_inference_time": 97.44100101194914,
      "std_inference_time": 10.233592979990929,
      "total_inference_time": 27.380921284357708,
      "throughput": 164.05583849241074,
      "confusion_matrix": [
        [
          2346,
          5
        ],
        [
          2,
          2139
        ]
      ],
      "classification_report_summary": {
        "Real": {
          "precision": 0.9991482112436116,
          "recall": 0.9978732454274777,
          "f1-score": 0.998510321344967,
          "support": 2351.0
        },
        "Fake": {
          "precision": 0.9976679104477612,
          "recall": 0.9990658570761326,
          "f1-score": 0.9983663943990665,
          "support": 2141.0
        },
        "accuracy": 0.9984416740872663,
        "macro avg": {
          "precision": 0.9984080608456865,
          "recall": 0.9984695512518051,
          "f1-score": 0.9984383578720167,
          "support": 4492.0
        },
        "weighted avg": {
          "precision": 0.9984426627120186,
          "recall": 0.9984416740872663,
          "f1-score": 0.9984417221483568,
          "support": 4492.0
        }
      }
    },
    "mobilebert": {
      "model": "MobileBERT",
      "accuracy": 0.9982190560997328,
      "precision": 0.9982207881131915,
      "recall": 0.9982190560997328,
      "f1_score": 0.9982191289803888,
      "precision_binary": 0.9972027972027973,
      "recall_binary": 0.9990658570761326,
      "f1_binary": 0.998133457769482,
      "precision_per_class": [
        0.9991478483170004,
        0.9972027972027973
      ],
      "recall_per_class": [
        0.9974478945129732,
        0.9990658570761326
      ],
      "f1_per_class": [
        0.998297147722435,
        0.998133457769482
      ],
      "support_per_class": [
        2351,
        2141
      ],
      "avg_inference_time": 131.43192548061748,
      "std_inference_time": 14.704482109859558,
      "total_inference_time": 36.932371060053505,
      "throughput": 121.62771766523815,
      "confusion_matrix": [
        [
          2345,
          6
        ],
        [
          2,
          2139
        ]
      ],
      "classification_report_summary": {
        "Real": {
          "precision": 0.9991478483170004,
          "recall": 0.9974478945129732,
          "f1-score": 0.998297147722435,
          "support": 2351.0
        },
        "Fake": {
          "precision": 0.9972027972027973,
          "recall": 0.9990658570761326,
          "f1-score": 0.998133457769482,
          "support": 2141.0
        },
        "accuracy": 0.9982190560997328,
        "macro avg": {
          "precision": 0.9981753227598988,
          "recall": 0.9982568757945529,
          "f1-score": 0.9982153027459586,
          "support": 4492.0
        },
        "weighted avg": {
          "precision": 0.9982207881131915,
          "recall": 0.9982190560997328,
          "f1-score": 0.9982191289803888,
          "support": 4492.0
        }
      }
    }
  }
}